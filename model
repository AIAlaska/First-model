from tensorflow.keras.models import Sequential  # Import the Sequential model class
from tensorflow.keras.layers import Dense, Flatten  # Import Dense and Flatten layers
from tensorflow.keras.datasets import mnist  # Import the MNIST dataset

# Define the model
model = Sequential([  # Create a Sequential model (layers are added sequentially)
    Flatten(input_shape=(28, 28)),  # Flatten the 28x28 input images into a 784-dimensional vector
    Dense(128, activation='relu'),  # Fully connected layer with 128 units and ReLU activation
    Dense(64, activation='relu'),  # Fully connected layer with 64 units and ReLU activation
    Dense(10, activation='softmax')  # Output layer with 10 units (for 10 digits) and softmax activation
])

# Compile the model
model.compile(optimizer='adam',  # Use the Adam optimizer
              loss='sparse_categorical_crossentropy',  # Use sparse categorical cross-entropy loss (for integer labels)
              metrics=['accuracy'])  # Track accuracy during training

# Load data
from tensorflow.keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()  # Load MNIST data into training and testing sets
x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to be between 0 and 1

# Train the model
model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))  # Train the model for 3 epochs, using x_test and y_test as validation data

# Save the trained model
model.save('mnist_model.h5')  # Save the entire model to a file named 'mnist_model.h5'
